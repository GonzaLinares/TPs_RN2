{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z-MxPGUy_gnh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkhi4OZS9A-1",
        "outputId": "508ce1da-3ce2-4cf2-a3ee-f2066c3ae51e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 03:39:36--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.96, 3.163.189.14, 3.163.189.108, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G   216MB/s    in 8.9s    \n",
            "\n",
            "2023-10-22 03:39:45 (163 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n",
            "Archive:  crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O Sherlock.txt https://www.gutenberg.org/ebooks/48320.txt.utf-8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsvPBlrbeORE",
        "outputId": "24a41b7e-e068-4aae-d6ec-d29d7a83d86a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 03:42:49--  https://www.gutenberg.org/ebooks/48320.txt.utf-8\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://www.gutenberg.org/cache/epub/48320/pg48320.txt [following]\n",
            "--2023-10-22 03:42:49--  http://www.gutenberg.org/cache/epub/48320/pg48320.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/cache/epub/48320/pg48320.txt [following]\n",
            "--2023-10-22 03:42:49--  https://www.gutenberg.org/cache/epub/48320/pg48320.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 622314 (608K) [text/plain]\n",
            "Saving to: ‘Sherlock.txt’\n",
            "\n",
            "Sherlock.txt        100%[===================>] 607.73K  1.69MB/s    in 0.4s    \n",
            "\n",
            "2023-10-22 03:42:50 (1.69 MB/s) - ‘Sherlock.txt’ saved [622314/622314]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WIz1vJra_6tw"
      },
      "outputs": [],
      "source": [
        "with open(\"Sherlock.txt\", 'r', encoding='utf-8') as file:\n",
        "    book = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|no|No)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
        "digits = \"([0-9])\"\n",
        "multiple_dots = r'\\.{2,}'\n",
        "\n",
        "def split_into_sentences(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Split the text into sentences.\n",
        "\n",
        "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead\n",
        "    to incorrect splitting because they are used as markers for splitting.\n",
        "\n",
        "    :param text: text to be split into sentences\n",
        "    :type text: str\n",
        "\n",
        "    :return: list of sentences\n",
        "    :rtype: list[str]\n",
        "    \"\"\"\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = ['<SOS> ' + s.strip() + ' <EOS>' for s in sentences]\n",
        "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "R2AZITlSf0Ms"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book = split_into_sentences(book)"
      ],
      "metadata": {
        "id": "bIDnuXWggX6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book[1000:1010]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oquhj3AngoVK",
        "outputId": "3a7049e3-0c18-4aa7-ac5d-961de84da472"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> I had come to the conclusion that he had dropped asleep, and indeed was nodding myself, when he suddenly sprang out of his chair with the gesture of a man who has made up his mind, and put his pipe down upon the mantel-piece. <EOS>',\n",
              " '<SOS> “Sarasate plays at the St. James’s Hall this afternoon,” he remarked. <EOS>',\n",
              " '<SOS> “What do you think, Watson? <EOS>',\n",
              " '<SOS> Could your patients spare you for a few hours? <EOS>',\n",
              " '<SOS> ”  “I have nothing to do to-day. <EOS>',\n",
              " '<SOS> My practice is never very absorbing”. <EOS>',\n",
              " '<SOS> “Then put on your hat and come. <EOS>',\n",
              " '<SOS> I am going through the city first, and we can have some lunch on the way. <EOS>',\n",
              " '<SOS> I observe that there is a good deal of German music on the programme, which is rather more to my taste than Italian or French. <EOS>',\n",
              " '<SOS> It is introspective, and I want to introspect. <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "Rs9yw_WhPxu7"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer(num_words=1000,\n",
        "                  filters='!\"“”#$%&()*+,.-/:;=?@[\\\\]^_`{|}~\\t\\n\\ufeff\\u2002', lower=True,\n",
        "                  split=' ', char_level=False, oov_token=\"UNK\")\n",
        "token.fit_on_texts(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "HOHSEmy-QAdg"
      },
      "outputs": [],
      "source": [
        "sequences = token.texts_to_sequences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Z-CwO8qihUjz"
      },
      "outputs": [],
      "source": [
        "textSequences = token.sequences_to_texts(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = len(max(sequences, key=len))"
      ],
      "metadata": {
        "id": "crHx5m7YkCNE"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "XZ73QhT5QAnX"
      },
      "outputs": [],
      "source": [
        "def create_dataset(sequences, maxSetPerSentence=3):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for i, sent in enumerate(sequences):\n",
        "        if len(sent) <= maxSetPerSentence+2:\n",
        "          continue\n",
        "\n",
        "        samples = np.random.choice(range(2, len(sent)), maxSetPerSentence, replace=False)\n",
        "        for j in samples:\n",
        "          inputs.append(sent[:j])\n",
        "          outputs.append(sent[j])\n",
        "\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "TPoB2Q4mQAq2"
      },
      "outputs": [],
      "source": [
        "X, y = create_dataset(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGVHjN62DXV",
        "outputId": "07566cc3-56fd-4561-b46f-c0e8a9039c8e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 147, 308, 880, 7, 881, 7, 124, 37, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCJdNDsZ2FEZ",
        "outputId": "84900f41-90a7-462a-9e29-df23520ca5cc"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "880"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "FKAsqcAja_G9"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(X, key=len))\n",
        "train_sequences = pad_sequences(X, maxlen=maxLen, padding=\"post\")\n",
        "train_sequences_y = np.array(y)\n",
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, update_display\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('./crawl-300d-2M.vec', encoding='utf-8')\n",
        "N = 2000000\n",
        "bar = IntProgress(min=0, max=N)\n",
        "ipd.display(bar)\n",
        "\n",
        "i = 0\n",
        "for n, line in enumerate(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    if n//(N//100) > i:\n",
        "          bar.value = n\n",
        "          i += 1\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9993dee5149347028ffbf0b4a50a507f",
            "3507ec684cb849a3b5cb456d531c0da7",
            "3a73ad16dd1e413ea5a27184cd3e6f07"
          ]
        },
        "id": "UP3R7ObLqGER",
        "outputId": "25007e62-035d-4c92-cf8e-3b8fee9daa5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=2000000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9993dee5149347028ffbf0b4a50a507f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 1999996 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "a_file = open(\"data.pkl\", \"wb\")\n",
        "pickle.dump(embeddings_index, a_file)\n",
        "a_file.close()\n"
      ],
      "metadata": {
        "id": "8VWl0UCL2kX3"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "cVwzHfDya_Au"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "Gmcxj7wAhUj0"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_sequences, train_sequences_y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "koANcVKYYk71"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, Reshape, BatchNormalization, LSTM\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "def softMaxOverTime(x):\n",
        "    return softmax(x, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "F82D6sTghUj1"
      },
      "outputs": [],
      "source": [
        "value_dim = 100 #Tamaño de los estados del contextualizador\n",
        "nb_words = num_words #Vocabulary size\n",
        "\n",
        "input_layer = Input(shape=(maxLen,)) #Cantidad maxima de la frase de entrada, estos son los timesteps para este caso\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxLen, trainable=False)(input_layer)\n",
        "\n",
        "#Contextualizador\n",
        "lstm_out = LSTM(value_dim, return_sequences=True, activation=\"tanh\")(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(lstm_out)\n",
        "\n",
        "#Attention\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([maxLen, value_dim])(repeated_attention)\n",
        "\n",
        "#Pesamos el embedding con el score\n",
        "weighted_embeddings = Multiply()([repeated_attention, lstm_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "#Salida\n",
        "dense1 = Dense(100, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(100, activation='relu')(dense1)\n",
        "dense3 = Dense(nb_words, activation='softmax')(dense2)\n",
        "model = Model(input_layer , dense3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gXMeBuhUj1",
        "outputId": "c8f19c54-7b0b-4a07-8a34-e8b2b5281e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 97)]              0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 97, 300)           2653200   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 97, 100)           160400    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 97, 100)           10100     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 97, 100)           10100     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 97, 8844)          893244    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3727044 (14.22 MB)\n",
            "Trainable params: 1073844 (4.10 MB)\n",
            "Non-trainable params: 2653200 (10.12 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "j0JRb8SNhUj1"
      },
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=0.5)\n",
        "callbackROP = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=10)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyPh--mhUj1",
        "outputId": "39d34593-062e-451a-89f8-054445e4cb8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=256, epochs=50, callbacks=[callbackROP])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toNum = token.texts_to_sequences([\"<SOS> Hello\"])"
      ],
      "metadata": {
        "id": "rWmzGoKM01ir"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aver = token.sequences_to_texts([[2]])"
      ],
      "metadata": {
        "id": "BKtJRd2D4dq9"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toNum = pad_sequences(toNum, maxlen=maxLen, padding=\"post\")"
      ],
      "metadata": {
        "id": "zG6H_pQo1ANY"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqkjWT0w0t3o",
        "outputId": "34309a44-c08a-4679-e4e4-a847aa49b55a"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "407/407 [==============================] - 3s 8ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9993dee5149347028ffbf0b4a50a507f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3507ec684cb849a3b5cb456d531c0da7",
            "max": 2000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a73ad16dd1e413ea5a27184cd3e6f07",
            "value": 1980000
          }
        },
        "3507ec684cb849a3b5cb456d531c0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a73ad16dd1e413ea5a27184cd3e6f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}