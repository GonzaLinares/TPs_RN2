{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z-MxPGUy_gnh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 541,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkhi4OZS9A-1",
        "outputId": "114109bb-e329-4428-a1ae-927c8d3237ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-27 05:12:07--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.238.206, 99.84.238.162, 99.84.238.154, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.238.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  15.0MB/s    in 39s     \n",
            "\n",
            "2023-10-27 05:12:47 (16.7 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "unzip:  cannot find or open wiki-news-300d-1M.zip, wiki-news-300d-1M.zip.zip or wiki-news-300d-1M.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!wget -O Sherlock.txt https://www.gutenberg.org/ebooks/48320.txt.utf-8\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {
        "id": "WIz1vJra_6tw"
      },
      "outputs": [],
      "source": [
        "with open(\"Sherlock.txt\", 'r', encoding='utf-8') as file:\n",
        "    book = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 533,
      "metadata": {
        "id": "R2AZITlSf0Ms"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|no|No)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
        "digits = \"([0-9])\"\n",
        "multiple_dots = r'\\.{2,}'\n",
        "\n",
        "def split_into_sentences(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Split the text into sentences.\n",
        "\n",
        "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead\n",
        "    to incorrect splitting because they are used as markers for splitting.\n",
        "\n",
        "    :param text: text to be split into sentences\n",
        "    :type text: str\n",
        "\n",
        "    :return: list of sentences\n",
        "    :rtype: list[str]\n",
        "    \"\"\"\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = ['<SOS> ' + s.strip() + ' <EOS>' for s in sentences]\n",
        "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 534,
      "metadata": {
        "id": "bIDnuXWggX6O"
      },
      "outputs": [],
      "source": [
        "book = split_into_sentences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oquhj3AngoVK",
        "outputId": "ecbeeeb2-7f78-4d90-9ff9-6326f2d793d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> I had come to the conclusion that he had dropped asleep, and indeed was nodding myself, when he suddenly sprang out of his chair with the gesture of a man who has made up his mind, and put his pipe down upon the mantel-piece. <EOS>',\n",
              " '<SOS> “Sarasate plays at the St. James’s Hall this afternoon,” he remarked. <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ],
      "source": [
        "book[1000:1002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 535,
      "metadata": {
        "id": "Rs9yw_WhPxu7"
      },
      "outputs": [],
      "source": [
        "maxTokens = 500\n",
        "token = Tokenizer(num_words=maxTokens,\n",
        "                  filters='!\"“”#$%&()*+,.-/:;=?@[\\\\]^_`{|}~\\t\\n\\ufeff\\u2002', lower=True,\n",
        "                  split=' ', char_level=False, oov_token=None)\n",
        "token.fit_on_texts(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 536,
      "metadata": {
        "id": "HOHSEmy-QAdg"
      },
      "outputs": [],
      "source": [
        "sequences = token.texts_to_sequences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "id": "crHx5m7YkCNE"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(sequences, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 537,
      "metadata": {
        "id": "XZ73QhT5QAnX"
      },
      "outputs": [],
      "source": [
        "def create_dataset(sequence):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for i, sent in enumerate(sequence):\n",
        "        for j in range(1, len(sent)-1):\n",
        "          inputs.append(sent[:j])\n",
        "          outputs.append([sent[j]])\n",
        "\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 538,
      "metadata": {
        "id": "TPoB2Q4mQAq2"
      },
      "outputs": [],
      "source": [
        "X, y = create_dataset(sequences)\n",
        "x_train = pad_sequences(X, maxlen=maxLen)\n",
        "y_train = np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGVHjN62DXV",
        "outputId": "a49b4a8f-53a1-42be-bb3d-881da4ae1d3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> adventure of the the gentleman in the it up to her a man entered the door was and all he sat in the sherlock holmes her about him like a in a they found the the us the ’ i cried ‘you are too at the of the stairs she met this']"
            ]
          },
          "metadata": {},
          "execution_count": 510
        }
      ],
      "source": [
        "token.sequences_to_texts([X[20]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 553,
      "metadata": {
        "id": "FKAsqcAja_G9"
      },
      "outputs": [],
      "source": [
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "num_words=len(dictionary)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 544,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "2882ef8f6e8447cbb64a78e9bed5cddb",
            "8a7b9d579fc14004baa9bfce838d09f7",
            "07ef1cf9f49045d68cef6a0cc9c48094"
          ]
        },
        "id": "UP3R7ObLqGER",
        "outputId": "5d3596ab-f5d5-4fee-8350-39c05c30ef4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=1000000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2882ef8f6e8447cbb64a78e9bed5cddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, update_display\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "#EMB = \"crawl-300d-2M.vec\"\n",
        "EMB = \"wiki-news-300d-1M.vec\"\n",
        "N = 1000000\n",
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(f'./{EMB}', encoding='utf-8')\n",
        "bar = IntProgress(min=0, max=N)\n",
        "ipd.display(bar)\n",
        "\n",
        "i = 0\n",
        "for n, line in enumerate(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    if n//(N//100) > i:\n",
        "          bar.value = n\n",
        "          i += 1\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 554,
      "metadata": {
        "id": "cVwzHfDya_Au"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "embedding_matrix=np.zeros([num_words, embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {
        "id": "koANcVKYYk71"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, Reshape, BatchNormalization\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "nb_words = len(embedding_matrix) #Vocabulary size\n",
        "embed_dim = len(embedding_matrix[0]) #Vectorization dim\n",
        "value_dim = 100\n",
        "maxLen = len(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 556,
      "metadata": {
        "id": "F82D6sTghUj1"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(maxLen,)) #Cantidad maxima de la frase de entrada, estos son los timesteps para este caso\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxLen, trainable=True)(input_layer)\n",
        "lstm_out = LSTM(value_dim, return_sequences=False, activation=\"tanh\")(embedding_layer)\n",
        "dense2 = Dense(nb_words, activation='softmax')(lstm_out)\n",
        "model = Model(input_layer, dense2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 549,
      "metadata": {
        "id": "85gXMeBuhUj1",
        "outputId": "5060a167-b844-4e93-c6de-b64512e30b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 94)]              0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, 94, 300)           2652900   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8843)              893143    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3706443 (14.14 MB)\n",
            "Trainable params: 3706443 (14.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 557,
      "metadata": {
        "id": "j0JRb8SNhUj1"
      },
      "outputs": [],
      "source": [
        "callbackROP = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
        "callbackES = EarlyStopping(monitor='val_loss', patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 558,
      "metadata": {
        "id": "ZosLpsQfwcdb"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 560,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyPh--mhUj1",
        "outputId": "bf7c2f71-9784-46a9-b20a-51bd2aafc198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "114/114 [==============================] - 11s 97ms/step - loss: 5.2693 - val_loss: 5.1044 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "114/114 [==============================] - 6s 49ms/step - loss: 5.0868 - val_loss: 5.0963 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "114/114 [==============================] - 4s 38ms/step - loss: 5.0748 - val_loss: 5.0609 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 4.9962 - val_loss: 4.9536 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 4.8849 - val_loss: 4.8396 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "114/114 [==============================] - 4s 38ms/step - loss: 4.7629 - val_loss: 4.7203 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "114/114 [==============================] - 5s 41ms/step - loss: 4.6498 - val_loss: 4.6133 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 4.5482 - val_loss: 4.5337 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "114/114 [==============================] - 4s 38ms/step - loss: 4.4747 - val_loss: 4.4782 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "114/114 [==============================] - 4s 38ms/step - loss: 4.4206 - val_loss: 4.4349 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.3759 - val_loss: 4.4004 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.3346 - val_loss: 4.3699 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 4.2984 - val_loss: 4.3427 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.2645 - val_loss: 4.3164 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 4.2326 - val_loss: 4.2948 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.2056 - val_loss: 4.2736 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 4.1798 - val_loss: 4.2584 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "114/114 [==============================] - 4s 36ms/step - loss: 4.1582 - val_loss: 4.2450 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.1380 - val_loss: 4.2315 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 4.1190 - val_loss: 4.2230 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 4.1014 - val_loss: 4.2121 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 4.0854 - val_loss: 4.2041 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 4.0701 - val_loss: 4.1944 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.0540 - val_loss: 4.1889 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 4.0405 - val_loss: 4.1814 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 4.0276 - val_loss: 4.1747 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 4.0145 - val_loss: 4.1726 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 4.0017 - val_loss: 4.1676 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.9895 - val_loss: 4.1622 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.9778 - val_loss: 4.1586 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.9661 - val_loss: 4.1523 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.9546 - val_loss: 4.1492 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 3.9437 - val_loss: 4.1469 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 3.9330 - val_loss: 4.1446 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 3.9216 - val_loss: 4.1392 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.9104 - val_loss: 4.1370 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 3.8999 - val_loss: 4.1353 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.8894 - val_loss: 4.1336 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.8789 - val_loss: 4.1300 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.8689 - val_loss: 4.1274 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.8593 - val_loss: 4.1264 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "114/114 [==============================] - 4s 36ms/step - loss: 3.8492 - val_loss: 4.1232 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.8391 - val_loss: 4.1231 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.8298 - val_loss: 4.1191 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 3.8205 - val_loss: 4.1199 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.8109 - val_loss: 4.1194 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "114/114 [==============================] - 4s 36ms/step - loss: 3.8016 - val_loss: 4.1178 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.7916 - val_loss: 4.1173 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.7832 - val_loss: 4.1169 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "114/114 [==============================] - 4s 35ms/step - loss: 3.7733 - val_loss: 4.1172 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bc463a7bdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 560
        }
      ],
      "source": [
        "model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=512, epochs=50, callbacks=[callbackROP, callbackES])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp-mOs7oPJr6"
      },
      "source": [
        "# Greedy search + T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 561,
      "metadata": {
        "id": "HvFeRI-lPJr7"
      },
      "outputs": [],
      "source": [
        "def changeTemp(a, temperature=1.0, epsilon=1e-10):\n",
        "    a = np.log(a) / temperature\n",
        "    sampled_temp = np.exp(a)/(np.exp(a).sum())\n",
        "    sampled_temp = sampled_temp/sampled_temp.sum()\n",
        "    return sampled_temp\n",
        "\n",
        "def greedy_search_withT(question, T):\n",
        "\n",
        "  out = 0\n",
        "  response = []\n",
        "  reply = question\n",
        "  finished = False\n",
        "\n",
        "  while out != token.texts_to_sequences([\"<eos>\"])[0][0] and not finished:\n",
        "      out = pad_sequences(reply, maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0)\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      out = np.random.choice(range(len(temp)), p=temp)\n",
        "      reply = [[out]]\n",
        "      if out in response:\n",
        "        finished = True\n",
        "      else:\n",
        "        response.append(out)\n",
        "\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = [1,1.2,0.5,0.6,0.8]\n",
        "plt.figure()\n",
        "plt.bar(range(len(arr1)), arr1, alpha=0.5)\n",
        "arr2 = changeTemp(arr1, temperature=1.0)\n",
        "plt.bar(range(len(arr2)), arr2, alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tLwZCSGoY17b",
        "outputId": "6e69bd58-c1f9-475e-de8c-eddfb745586d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = token.texts_to_sequences([\"<sos> the case\"])"
      ],
      "metadata": {
        "id": "rqHcaXMI5yu0"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_seq_to_text(seq):\n",
        "    return token.sequences_to_texts([seq])\n",
        "\n",
        "response = greedy_search_withT(question, T=1.2)\n",
        "rta = from_seq_to_text(response)\n",
        "rta"
      ],
      "metadata": {
        "id": "Cc5_Ya5lPdV-",
        "outputId": "9025cafd-0aae-4df2-b57c-b00cbf97a7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it something since yourself from all then that']"
            ]
          },
          "metadata": {},
          "execution_count": 579
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic beam search + T"
      ],
      "metadata": {
        "id": "ucj0WhQ3bt5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(kBeams, maxOutputLen, candidates):\n",
        "\n",
        "  if maxOutputLen < 1:\n",
        "    return [[]]*kBeams, [1]*kBeams\n",
        "  else:\n",
        "    for curr in candidates:\n",
        "      out = pad_sequences([curr], maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0) #Probabilidades\n",
        "      newCandidates = np.argsort(out[0])[::-1][:kBeams] #Agarramos los indices de los k-elementos con mas prob\n",
        "      newCandProba = [out[0][i] for i in newCandidates] #Agarramos su probabilidad\n",
        "      newCandidates = [[num] for num in newCandidates] #Convertimos los numeros en listas de numeros por compatibilidad con pad_sequences\n",
        "\n",
        "      print(newCandProba)\n",
        "      print(newCandidates)\n",
        "\n",
        "    return np.concatenate((newCandidates, beam_search(kBeams, maxOutputLen-1, newCandidates)[0]), axis=1), np.multiply(newCandProba,  beam_search(kBeams, maxOutputLen-1, newCandidates)[1])"
      ],
      "metadata": {
        "id": "wH5B8sP2bpQw"
      },
      "execution_count": 528,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = token.texts_to_sequences([\"<sos> sherlock holmes\"])"
      ],
      "metadata": {
        "id": "PtnJvuQAbqjA"
      },
      "execution_count": 529,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.sequences_to_texts([[15]])"
      ],
      "metadata": {
        "id": "4v6rn7abeu-2",
        "outputId": "de1e5dc4-1a0c-48e3-80ce-089edae87ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['his']"
            ]
          },
          "metadata": {},
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxOutputLen = 2\n",
        "kBeams = 2\n",
        "candidates = question\n",
        "\n",
        "outSeq, outProb = beam_search(kBeams, maxOutputLen, candidates)\n",
        "result = token.sequences_to_texts(outSeq)\n",
        "\n",
        "for i, sent in enumerate(result):\n",
        "  print(f\"prob: {outProb[i]:.2f} - Rta: {sent}\")"
      ],
      "metadata": {
        "id": "whbxNptz51Lp",
        "outputId": "4f0fe058-81ba-4e73-a2a7-17cbd8ac0e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9992136, 1.3436535e-07]\n",
            "[[2], [1659]]\n",
            "[0.9991141, 1.5084032e-07]\n",
            "[[2], [1659]]\n",
            "[0.9991505, 1.4481573e-07]\n",
            "[[2], [1659]]\n",
            "[0.9991141, 1.5084032e-07]\n",
            "[[2], [1659]]\n",
            "[0.9991505, 1.4481573e-07]\n",
            "[[2], [1659]]\n",
            "prob: 1.00 - Rta: <eos> <eos>\n",
            "prob: 0.00 - Rta: \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2882ef8f6e8447cbb64a78e9bed5cddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7b9d579fc14004baa9bfce838d09f7",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07ef1cf9f49045d68cef6a0cc9c48094",
            "value": 990000
          }
        },
        "8a7b9d579fc14004baa9bfce838d09f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ef1cf9f49045d68cef6a0cc9c48094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}