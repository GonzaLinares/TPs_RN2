{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z-MxPGUy_gnh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkhi4OZS9A-1",
        "outputId": "0724f4c8-cd16-4542-9dd5-cd08d572e990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 02:28:39--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.111, 13.226.210.78, 13.226.210.25, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  16.2MB/s    in 36s     \n",
            "\n",
            "2023-10-31 02:29:15 (18.2 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "--2023-10-31 02:29:16--  https://www.gutenberg.org/ebooks/48320.txt.utf-8\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://www.gutenberg.org/cache/epub/48320/pg48320.txt [following]\n",
            "--2023-10-31 02:29:16--  http://www.gutenberg.org/cache/epub/48320/pg48320.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/cache/epub/48320/pg48320.txt [following]\n",
            "--2023-10-31 02:29:16--  https://www.gutenberg.org/cache/epub/48320/pg48320.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 622314 (608K) [text/plain]\n",
            "Saving to: ‘Sherlock.txt’\n",
            "\n",
            "Sherlock.txt        100%[===================>] 607.73K  1.66MB/s    in 0.4s    \n",
            "\n",
            "2023-10-31 02:29:17 (1.66 MB/s) - ‘Sherlock.txt’ saved [622314/622314]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!wget -O Sherlock.txt https://www.gutenberg.org/ebooks/48320.txt.utf-8\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WIz1vJra_6tw"
      },
      "outputs": [],
      "source": [
        "with open(\"Sherlock.txt\", 'r', encoding='utf-8') as file:\n",
        "    book = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R2AZITlSf0Ms"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|no|No)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
        "digits = \"([0-9])\"\n",
        "multiple_dots = r'\\.{2,}'\n",
        "\n",
        "def split_into_sentences(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Split the text into sentences.\n",
        "\n",
        "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead\n",
        "    to incorrect splitting because they are used as markers for splitting.\n",
        "\n",
        "    :param text: text to be split into sentences\n",
        "    :type text: str\n",
        "\n",
        "    :return: list of sentences\n",
        "    :rtype: list[str]\n",
        "    \"\"\"\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = ['<SOS> ' + s.strip() + ' <EOS>' for s in sentences]\n",
        "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bIDnuXWggX6O"
      },
      "outputs": [],
      "source": [
        "book = split_into_sentences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oquhj3AngoVK",
        "outputId": "64a52e13-4903-4827-a527-9e8669ee56ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> I had come to the conclusion that he had dropped asleep, and indeed was nodding myself, when he suddenly sprang out of his chair with the gesture of a man who has made up his mind, and put his pipe down upon the mantel-piece. <EOS>',\n",
              " '<SOS> “Sarasate plays at the St. James’s Hall this afternoon,” he remarked. <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "book[1000:1002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rs9yw_WhPxu7"
      },
      "outputs": [],
      "source": [
        "maxTokens = 5000\n",
        "token = Tokenizer(num_words=maxTokens,\n",
        "                  filters='!\"“”#$%&()*+,.-/:;=?@[\\\\]^_`{|}~\\t\\n\\ufeff\\u2002', lower=True,\n",
        "                  split=' ', char_level=False, oov_token=None)\n",
        "token.fit_on_texts(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HOHSEmy-QAdg"
      },
      "outputs": [],
      "source": [
        "sequences = token.texts_to_sequences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "crHx5m7YkCNE"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(sequences, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDGrD4Im-oJl",
        "outputId": "271d0da9-e8f6-4651-efc3-1655fa837d57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "maxLen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XZ73QhT5QAnX"
      },
      "outputs": [],
      "source": [
        "def create_dataset(sequence):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for i, sent in enumerate(sequence):\n",
        "        for j in range(1, len(sent)-1):\n",
        "          inputs.append(sent[:j])\n",
        "          outputs.append([sent[j]])\n",
        "\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TPoB2Q4mQAq2"
      },
      "outputs": [],
      "source": [
        "X, y = create_dataset(sequences)\n",
        "x_train = pad_sequences(X, maxlen=maxLen)\n",
        "y_train = np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGVHjN62DXV",
        "outputId": "0165af72-a0ca-4166-9721-aa83fb1761e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the project gutenberg ebook of adventures of sherlock holmes this ebook is for the use of anyone anywhere in the']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "token.sequences_to_texts([X[20]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FKAsqcAja_G9"
      },
      "outputs": [],
      "source": [
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "num_words=len(dictionary)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a5e2d6bdd4394051bc9becb19b0de174",
            "8657f11a1e2f41148357bf2301b69284",
            "dbc641bb507243b6b4c6d8595b355dfa"
          ]
        },
        "id": "UP3R7ObLqGER",
        "outputId": "e5b1a0c9-ede4-47b1-9b26-91f54a3977c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=1000000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5e2d6bdd4394051bc9becb19b0de174"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, update_display\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "EMB = \"wiki-news-300d-1M.vec\"\n",
        "N = 1000000\n",
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(f'./{EMB}', encoding='utf-8')\n",
        "bar = IntProgress(min=0, max=N)\n",
        "ipd.display(bar)\n",
        "\n",
        "i = 0\n",
        "for n, line in enumerate(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    if n//(N//100) > i:\n",
        "          bar.value = n\n",
        "          i += 1\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cVwzHfDya_Au"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "embedding_matrix=np.zeros([num_words, embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "koANcVKYYk71"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, Reshape, BatchNormalization\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "nb_words = len(embedding_matrix) #Vocabulary size\n",
        "embed_dim = len(embedding_matrix[0]) #Vectorization dim\n",
        "value_dim = 100\n",
        "maxLen = len(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "F82D6sTghUj1"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(maxLen,)) #Cantidad maxima de la frase de entrada, estos son los timesteps para este caso\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxLen, trainable=True)(input_layer)\n",
        "lstm = LSTM(value_dim, return_sequences=False, activation=\"tanh\")(embedding_layer)\n",
        "drop = Dropout(0.4)(lstm)\n",
        "dense2 = Dense(nb_words, activation='softmax')(drop)\n",
        "model = Model(inputs=input_layer, outputs=dense2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gXMeBuhUj1",
        "outputId": "de7484a8-7142-4d6e-c3c6-b1456a6b5827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 153)]             0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 153, 300)          2652900   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8843)              893143    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3706443 (14.14 MB)\n",
            "Trainable params: 3706443 (14.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "j0JRb8SNhUj1"
      },
      "outputs": [],
      "source": [
        "callbackROP = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
        "callbackES = EarlyStopping(monitor='val_loss', patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZosLpsQfwcdb"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyPh--mhUj1",
        "outputId": "b530185a-faa7-4a6f-c478-0dda04f5d3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "147/147 [==============================] - 19s 113ms/step - loss: 6.7715 - val_loss: 6.2798 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "147/147 [==============================] - 12s 78ms/step - loss: 6.1735 - val_loss: 6.1797 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "147/147 [==============================] - 8s 57ms/step - loss: 6.0282 - val_loss: 6.0404 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "147/147 [==============================] - 9s 61ms/step - loss: 5.8394 - val_loss: 5.8594 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "147/147 [==============================] - 10s 65ms/step - loss: 5.6678 - val_loss: 5.7441 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "147/147 [==============================] - 8s 58ms/step - loss: 5.5409 - val_loss: 5.6706 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 5.4434 - val_loss: 5.6187 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 5.3612 - val_loss: 5.5737 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 5.2848 - val_loss: 5.5347 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 5.2167 - val_loss: 5.5023 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "147/147 [==============================] - 8s 54ms/step - loss: 5.1523 - val_loss: 5.4703 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 5.0902 - val_loss: 5.4460 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "147/147 [==============================] - 8s 54ms/step - loss: 5.0321 - val_loss: 5.4221 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 4.9810 - val_loss: 5.4044 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.9266 - val_loss: 5.3895 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 4.8795 - val_loss: 5.3743 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 4.8309 - val_loss: 5.3629 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.7876 - val_loss: 5.3557 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.7426 - val_loss: 5.3462 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "147/147 [==============================] - 10s 66ms/step - loss: 4.7024 - val_loss: 5.3399 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "147/147 [==============================] - 10s 69ms/step - loss: 4.6603 - val_loss: 5.3367 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.6210 - val_loss: 5.3334 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 4.5778 - val_loss: 5.3310 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.5382 - val_loss: 5.3277 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 4.4998 - val_loss: 5.3265 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 4.4602 - val_loss: 5.3266 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.4229 - val_loss: 5.3311 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.3821 - val_loss: 5.3307 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.3481 - val_loss: 5.3372 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 4.3131 - val_loss: 5.3405 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.2561 - val_loss: 5.3399 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 4.2366 - val_loss: 5.3429 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.2198 - val_loss: 5.3474 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.1972 - val_loss: 5.3519 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.1789 - val_loss: 5.3577 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a2e705bd5a0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=512, epochs=50, callbacks=[callbackROP, callbackES])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Greedy search + ArgMax"
      ],
      "metadata": {
        "id": "3gpFgMjFeLcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(question, max_len):\n",
        "\n",
        "  out = 0\n",
        "  response = []\n",
        "  reply = question\n",
        "  finished = False\n",
        "\n",
        "  while out != token.texts_to_sequences([\"<eos>\"])[0][0] and len(response) < max_len:\n",
        "      out = pad_sequences(reply, maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0)\n",
        "      out = int(np.argmax(out))\n",
        "      reply[0] += [out]\n",
        "      if out in response:\n",
        "        finished = True\n",
        "      else:\n",
        "        response.append(out)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "N3RUZ8SUeMMm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = token.texts_to_sequences([\"<sos> sherlock\"])"
      ],
      "metadata": {
        "id": "3A8POxoleX2i"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_seq_to_text(seq):\n",
        "    return token.sequences_to_texts([seq])\n",
        "\n",
        "response = greedy_search(question, max_len=15)\n",
        "rta = from_seq_to_text(response)\n",
        "rta"
      ],
      "metadata": {
        "id": "gZIlKOhaecsY",
        "outputId": "84e262c3-5295-405c-a246-b0ef809e40bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['holmes was a little man who had been of the centre house city project gutenberg™']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp-mOs7oPJr6"
      },
      "source": [
        "# Greedy search + T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "HvFeRI-lPJr7"
      },
      "outputs": [],
      "source": [
        "def changeTemp(a, temperature=1.0, epsilon=1e-10):\n",
        "    a = np.log(a+1e-10) / temperature\n",
        "    sampled_temp = np.exp(a+1e-10)/(np.exp(a+1e-10).sum())\n",
        "    sampled_temp = sampled_temp/sampled_temp.sum()\n",
        "    return sampled_temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search_withT(question, max_len=15, T=1.0):\n",
        "\n",
        "  out = 0\n",
        "  response = []\n",
        "  reply = question\n",
        "  finished = False\n",
        "  eof = token.texts_to_sequences([\"<eos>\"])[0][0]\n",
        "\n",
        "  while out != eof and len(response) < max_len:\n",
        "\n",
        "      out = pad_sequences(reply, maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0)\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      out = np.random.choice(range(len(temp)), p=temp)\n",
        "      reply[0] += [out]\n",
        "      if out in response:\n",
        "        finished = True\n",
        "      else:\n",
        "        response.append(out)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "DbUWjR8m4rE1"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tLwZCSGoY17b",
        "outputId": "be11cfb5-c37f-4cb1-901b-0f48bb14f1f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "arr1 = [1,1.2,0.5,0.6,0.8]\n",
        "plt.figure()\n",
        "plt.bar(range(len(arr1)), arr1, alpha=0.5)\n",
        "arr2 = changeTemp(arr1, temperature=1.1)\n",
        "plt.bar(range(len(arr2)), arr2, alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "rqHcaXMI5yu0"
      },
      "outputs": [],
      "source": [
        "question = token.texts_to_sequences([\"<sos> sherlock\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc5_Ya5lPdV-",
        "outputId": "11ef947e-efe0-43c0-f513-a689a132270a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['holmes rushed away home fixed two very well of honest investments through assisting when just']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "def from_seq_to_text(seq):\n",
        "    return token.sequences_to_texts([seq])\n",
        "\n",
        "response = greedy_search_withT(question, max_len=15, T=1.4)\n",
        "rta = from_seq_to_text(response)\n",
        "rta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucj0WhQ3bt5k"
      },
      "source": [
        "# Stochastic beam search + T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "wH5B8sP2bpQw"
      },
      "outputs": [],
      "source": [
        "def beam_search(kBeams, maxOutputLen, candidates, T=1.0):\n",
        "\n",
        "  if maxOutputLen < 1:\n",
        "    return [[]]*kBeams, [1]*kBeams\n",
        "  else:\n",
        "    for curr in candidates:\n",
        "\n",
        "      out = pad_sequences([curr], maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0) #Probabilidades\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      newCandidates = np.argsort(temp)[::-1][:kBeams] #Agarramos los indices de los k-elementos con mas prob\n",
        "      newCandProba = [temp[i] for i in newCandidates] #Agarramos su probabilidad\n",
        "      newCandidates = [[num] for num in newCandidates] #Convertimos los numeros en listas de numeros por compatibilidad con pad_sequences\n",
        "\n",
        "    if len(candidates) != 1:\n",
        "        concatenated = np.concatenate((candidates, newCandidates), axis=1)\n",
        "    else:\n",
        "        concatenated = newCandidates\n",
        "\n",
        "    return np.concatenate((newCandidates, beam_search(kBeams, maxOutputLen-1, concatenated)[0]), axis=1), np.multiply(newCandProba,  beam_search(kBeams, maxOutputLen-1, concatenated)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "PtnJvuQAbqjA"
      },
      "outputs": [],
      "source": [
        "question = token.texts_to_sequences([\"<sos>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whbxNptz51Lp",
        "outputId": "51955675-e3b0-4ec4-ceab-c72d94c2223b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob: 0.00 - Rta: i have be to of the was\n",
            "prob: 0.00 - Rta: it had have from from a is\n",
            "prob: 0.00 - Rta: the were not back to his would\n",
            "prob: 0.00 - Rta: ’ shall find for in my and\n",
            "prob: 0.00 - Rta: he may see at for this in\n",
            "prob: 0.00 - Rta: you are go in the some had\n",
            "prob: 0.00 - Rta: but will do into upon an seemed\n",
            "prob: 0.00 - Rta: and found think upon into one has\n",
            "prob: 0.00 - Rta: there must take with and its on\n",
            "prob: 0.00 - Rta: we should come out by it might\n"
          ]
        }
      ],
      "source": [
        "maxOutputLen = 7\n",
        "kBeams = 10\n",
        "candidates = question\n",
        "\n",
        "outSeq, outProb = beam_search(kBeams, maxOutputLen, candidates, T=1.1)\n",
        "result = token.sequences_to_texts(outSeq)\n",
        "\n",
        "for i, sent in enumerate(result):\n",
        "  print(f\"prob: {outProb[i]:.2f} - Rta: {sent}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5e2d6bdd4394051bc9becb19b0de174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8657f11a1e2f41148357bf2301b69284",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbc641bb507243b6b4c6d8595b355dfa",
            "value": 990000
          }
        },
        "8657f11a1e2f41148357bf2301b69284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc641bb507243b6b4c6d8595b355dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}