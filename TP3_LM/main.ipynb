{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "id": "Z-MxPGUy_gnh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkhi4OZS9A-1"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!wget -O Sherlock.txt https://www.gutenberg.org/ebooks/48320.txt.utf-8\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "id": "WIz1vJra_6tw"
      },
      "outputs": [],
      "source": [
        "with open(\"Sherlock.txt\", 'r', encoding='utf-8') as file:\n",
        "    book = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "R2AZITlSf0Ms"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|no|No)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
        "digits = \"([0-9])\"\n",
        "multiple_dots = r'\\.{2,}'\n",
        "\n",
        "def split_into_sentences(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Split the text into sentences.\n",
        "\n",
        "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead\n",
        "    to incorrect splitting because they are used as markers for splitting.\n",
        "\n",
        "    :param text: text to be split into sentences\n",
        "    :type text: str\n",
        "\n",
        "    :return: list of sentences\n",
        "    :rtype: list[str]\n",
        "    \"\"\"\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = ['<SOS> ' + s.strip() + ' <EOS>' for s in sentences]\n",
        "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "id": "bIDnuXWggX6O"
      },
      "outputs": [],
      "source": [
        "book = split_into_sentences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oquhj3AngoVK",
        "outputId": "d10a1c27-58ab-48d9-ab9c-c6923f323f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> I had come to the conclusion that he had dropped asleep, and indeed was nodding myself, when he suddenly sprang out of his chair with the gesture of a man who has made up his mind, and put his pipe down upon the mantel-piece. <EOS>',\n",
              " '<SOS> “Sarasate plays at the St. James’s Hall this afternoon,” he remarked. <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ],
      "source": [
        "book[1000:1002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {
        "id": "Rs9yw_WhPxu7"
      },
      "outputs": [],
      "source": [
        "maxTokens = 5000\n",
        "token = Tokenizer(num_words=maxTokens,\n",
        "                  filters='!\"“”#$%&()*+,.-/:;=?@[\\\\]^_`{|}~\\t\\n\\ufeff\\u2002', lower=True,\n",
        "                  split=' ', char_level=False, oov_token=None)\n",
        "token.fit_on_texts(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "HOHSEmy-QAdg"
      },
      "outputs": [],
      "source": [
        "sequences = token.texts_to_sequences(book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {
        "id": "crHx5m7YkCNE"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(sequences, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDGrD4Im-oJl"
      },
      "outputs": [],
      "source": [
        "maxLen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "XZ73QhT5QAnX"
      },
      "outputs": [],
      "source": [
        "def create_dataset(sequence):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for i, sent in enumerate(sequence):\n",
        "        for j in range(1, len(sent)-1):\n",
        "          inputs.append(sent[:j])\n",
        "          outputs.append([sent[j]])\n",
        "\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "id": "TPoB2Q4mQAq2"
      },
      "outputs": [],
      "source": [
        "X, y = create_dataset(sequences)\n",
        "x_train = pad_sequences(X, maxlen=maxLen)\n",
        "y_train = np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGVHjN62DXV",
        "outputId": "44a5d883-608e-4ceb-d855-2bcecff90cb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the project gutenberg ebook of adventures of sherlock holmes this ebook is for the use of anyone anywhere in the']"
            ]
          },
          "metadata": {},
          "execution_count": 449
        }
      ],
      "source": [
        "token.sequences_to_texts([X[20]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "FKAsqcAja_G9"
      },
      "outputs": [],
      "source": [
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "num_words=len(dictionary)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f420786d0a574b3ca83d292cee46598f",
            "b326df92dc2449f1b59bc465eaa22c73",
            "d413ec225b2446fbbe79281979d78e7d"
          ]
        },
        "id": "UP3R7ObLqGER",
        "outputId": "a4449635-269a-4ba4-941f-50f2d23546f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=1000000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f420786d0a574b3ca83d292cee46598f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, update_display\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "EMB = \"wiki-news-300d-1M.vec\"\n",
        "N = 1000000\n",
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(f'./{EMB}', encoding='utf-8')\n",
        "bar = IntProgress(min=0, max=N)\n",
        "ipd.display(bar)\n",
        "\n",
        "i = 0\n",
        "for n, line in enumerate(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    if n//(N//100) > i:\n",
        "          bar.value = n\n",
        "          i += 1\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "cVwzHfDya_Au"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "embedding_matrix=np.zeros([num_words, embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {
        "id": "koANcVKYYk71"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, Reshape, BatchNormalization\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "nb_words = len(embedding_matrix) #Vocabulary size\n",
        "embed_dim = len(embedding_matrix[0]) #Vectorization dim\n",
        "value_dim = 100\n",
        "maxLen = len(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {
        "id": "F82D6sTghUj1"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(maxLen,)) #Cantidad maxima de la frase de entrada, estos son los timesteps para este caso\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxLen, trainable=True)(input_layer)\n",
        "lstm = LSTM(value_dim, return_sequences=False, activation=\"tanh\")(embedding_layer)\n",
        "drop = Dropout(0.4)(lstm)\n",
        "dense2 = Dense(nb_words, activation='softmax')(drop)\n",
        "model = Model(inputs=input_layer, outputs=dense2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gXMeBuhUj1",
        "outputId": "622fb713-6488-4ea3-84e6-46c012f7dee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 153)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 153, 300)          2652900   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8843)              893143    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3706443 (14.14 MB)\n",
            "Trainable params: 3706443 (14.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {
        "id": "j0JRb8SNhUj1"
      },
      "outputs": [],
      "source": [
        "callbackROP = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
        "callbackES = EarlyStopping(monitor='val_loss', patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "id": "ZosLpsQfwcdb"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyPh--mhUj1",
        "outputId": "5334c1b6-075f-4bda-c84c-b61deaa4a868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "147/147 [==============================] - 21s 119ms/step - loss: 6.7922 - val_loss: 6.3028 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "147/147 [==============================] - 11s 76ms/step - loss: 6.1827 - val_loss: 6.2012 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "147/147 [==============================] - 10s 67ms/step - loss: 6.0517 - val_loss: 6.0956 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "147/147 [==============================] - 8s 57ms/step - loss: 5.9073 - val_loss: 5.9418 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "147/147 [==============================] - 10s 71ms/step - loss: 5.7447 - val_loss: 5.8113 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "147/147 [==============================] - 11s 73ms/step - loss: 5.6116 - val_loss: 5.7252 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "147/147 [==============================] - 9s 62ms/step - loss: 5.5133 - val_loss: 5.6727 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 5.4328 - val_loss: 5.6293 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 5.3624 - val_loss: 5.5960 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 5.3014 - val_loss: 5.5629 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "147/147 [==============================] - 8s 51ms/step - loss: 5.2453 - val_loss: 5.5350 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 5.1914 - val_loss: 5.5130 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 5.1389 - val_loss: 5.4880 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 5.0907 - val_loss: 5.4686 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 5.0433 - val_loss: 5.4493 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.9975 - val_loss: 5.4338 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "147/147 [==============================] - 8s 54ms/step - loss: 4.9538 - val_loss: 5.4202 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.9139 - val_loss: 5.4067 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.8747 - val_loss: 5.3991 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.8337 - val_loss: 5.3898 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.7939 - val_loss: 5.3849 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "147/147 [==============================] - 8s 56ms/step - loss: 4.7627 - val_loss: 5.3787 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.7254 - val_loss: 5.3776 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "147/147 [==============================] - 8s 55ms/step - loss: 4.6929 - val_loss: 5.3729 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "147/147 [==============================] - 8s 56ms/step - loss: 4.6642 - val_loss: 5.3706 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "147/147 [==============================] - 8s 57ms/step - loss: 4.6294 - val_loss: 5.3723 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.6014 - val_loss: 5.3724 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 4.5712 - val_loss: 5.3733 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 4.5426 - val_loss: 5.3747 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "147/147 [==============================] - 8s 51ms/step - loss: 4.5134 - val_loss: 5.3790 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.4647 - val_loss: 5.3783 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "147/147 [==============================] - 8s 54ms/step - loss: 4.4497 - val_loss: 5.3796 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "147/147 [==============================] - 8s 54ms/step - loss: 4.4352 - val_loss: 5.3815 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 4.4196 - val_loss: 5.3850 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 4.4043 - val_loss: 5.3873 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e9d8edb5e70>"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ],
      "source": [
        "model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=512, epochs=50, callbacks=[callbackROP, callbackES])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Greedy search + ArgMax"
      ],
      "metadata": {
        "id": "3gpFgMjFeLcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(question, outputLen):\n",
        "\n",
        "  out = 0\n",
        "  response = []\n",
        "  reply = question\n",
        "  finished = False\n",
        "\n",
        "  while out != token.texts_to_sequences([\"<eos>\"])[0][0] and len(response) < outputLen:\n",
        "      out = pad_sequences(reply, maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0)\n",
        "      out = int(np.argmax(out))\n",
        "      reply[0] += [out]\n",
        "      response.append(out)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "N3RUZ8SUeMMm"
      },
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = token.texts_to_sequences([\"<sos> sherlock\"])"
      ],
      "metadata": {
        "id": "3A8POxoleX2i"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_seq_to_text(seq):\n",
        "    return token.sequences_to_texts([seq])\n",
        "\n",
        "response = greedy_search(question, outputLen=15)\n",
        "rta = from_seq_to_text(response)\n",
        "rta"
      ],
      "metadata": {
        "id": "gZIlKOhaecsY",
        "outputId": "b2d2bfaf-11db-4f85-ea34-e20b4e785cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['holmes and i have been a little more than the matter was a very man']"
            ]
          },
          "metadata": {},
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp-mOs7oPJr6"
      },
      "source": [
        "# Greedy search + T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 633,
      "metadata": {
        "id": "HvFeRI-lPJr7"
      },
      "outputs": [],
      "source": [
        "def changeTemp(a, temperature=1.0, epsilon=1e-10):\n",
        "    a = np.log(a) / temperature\n",
        "    sampled_temp = np.exp(a+1e-10)/(np.exp(a+1e-10).sum())\n",
        "    sampled_temp = sampled_temp/sampled_temp.sum()\n",
        "    return sampled_temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search_withT(question, max_len=15, T=1.0):\n",
        "\n",
        "  out = 0\n",
        "  response = []\n",
        "  reply = question\n",
        "  finished = False\n",
        "  eof = token.texts_to_sequences([\"<eos>\"])[0][0]\n",
        "\n",
        "  while out != eof and len(response) < max_len:\n",
        "\n",
        "      out = pad_sequences(reply, maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0)\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      out = np.random.choice(range(len(temp)), p=temp)\n",
        "      reply[0] += [out]\n",
        "      if out in response:\n",
        "        finished = True\n",
        "      else:\n",
        "        response.append(out)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "DbUWjR8m4rE1"
      },
      "execution_count": 634,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tLwZCSGoY17b",
        "outputId": "2b73d854-efed-42d0-8f41-79f726b2e088"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "arr1 = [1, 1.2, 0.5, 0.6, 0.8]\n",
        "plt.figure()\n",
        "plt.bar(range(len(arr1)), arr1, alpha=0.5)\n",
        "arr2 = changeTemp(arr1, temperature=2.1)\n",
        "plt.bar(range(len(arr2)), arr2, alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 638,
      "metadata": {
        "id": "rqHcaXMI5yu0"
      },
      "outputs": [],
      "source": [
        "question = token.texts_to_sequences([\"<sos> watson there is\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 639,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc5_Ya5lPdV-",
        "outputId": "a32dd39b-145d-41da-b8fd-ecf383281c21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a very often fell for some being found upon the darkness of shape great folk']"
            ]
          },
          "metadata": {},
          "execution_count": 639
        }
      ],
      "source": [
        "def from_seq_to_text(seq):\n",
        "    return token.sequences_to_texts([seq])\n",
        "\n",
        "response = greedy_search_withT(question, max_len=15, T=0.9)\n",
        "rta = from_seq_to_text(response)\n",
        "rta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucj0WhQ3bt5k"
      },
      "source": [
        "# Stochastic beam search + T (most probable path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 666,
      "metadata": {
        "id": "wH5B8sP2bpQw"
      },
      "outputs": [],
      "source": [
        "def stoch_beam_search(kBeams, maxOutputLen, candidatesAndProb, T=1.0):\n",
        "\n",
        "  candidates = candidatesAndProb[0]\n",
        "  probabilities = candidatesAndProb[1]\n",
        "\n",
        "  if maxOutputLen < 1:\n",
        "    return candidates, probabilities\n",
        "  else:\n",
        "\n",
        "    possibleCand = [0]*kBeams\n",
        "    possibleProb = [0]*kBeams\n",
        "\n",
        "    #Calculamos los candidatos para cada rama, kBeams candidatos maximos\n",
        "    for curr in candidates:\n",
        "      out = pad_sequences([curr], maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0) #Probabilidades\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      newCandidates = np.argsort(temp)[::-1][:kBeams] #Agarramos los indices de los k-elementos con mas prob\n",
        "      newCandidates = [[num] for num in newCandidates] #Convertimos los numeros en listas de numeros por compatibilidad con pad_sequences\n",
        "      newCandProba = [temp[i] for i in newCandidates] #Agarramos su probabilidad\n",
        "\n",
        "      #Elegimos los kBeams caminos con mas probabilidad\n",
        "      for i, prob in enumerate(newCandProba): #Agarramos la probabilidad de cada candidato\n",
        "        for j in range(len(possibleProb)): #Para cada probabilidad maxima guardada\n",
        "          if possibleProb[j] < prob and newCandProba[i] not in possibleCand:\n",
        "            possibleProb[j] = prob\n",
        "            possibleCand[j] = newCandProba[i]\n",
        "\n",
        "    #print(possibleCand)\n",
        "    #print(possibleProb)\n",
        "\n",
        "    concatenated = np.concatenate((candidates, newCandidates), axis=1)\n",
        "    probabilities = np.multiply(probabilities, newCandProba)\n",
        "\n",
        "    #print(concatenated)\n",
        "    #print(probabilities)\n",
        "\n",
        "    return stoch_beam_search(kBeams, maxOutputLen-1, (concatenated, probabilities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 667,
      "metadata": {
        "id": "PtnJvuQAbqjA"
      },
      "outputs": [],
      "source": [
        "question = token.texts_to_sequences([\"<sos> watson was walking\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 673,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whbxNptz51Lp",
        "outputId": "7dd08f11-7a1a-4a0c-937c-de827f64ab41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob: 0.0000000039 - Rta: <sos> watson was walking into in the way and i been a the hands\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking in the a morning to was a the a own\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking at and his man upon is not it my eyes\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking and to my agreement with he no to this face\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking down into this matter which has done in his chair\n"
          ]
        }
      ],
      "source": [
        "maxOutputLen = 10\n",
        "kBeams = 5\n",
        "candidates = (question*kBeams, 1*kBeams)\n",
        "\n",
        "outSeq, outProb = stoch_beam_search(kBeams, maxOutputLen, candidates, T=1.1)\n",
        "result = token.sequences_to_texts(outSeq)\n",
        "\n",
        "for i, sent in enumerate(result):\n",
        "  print(f\"prob: {outProb[i][0]:.10f} - Rta: {sent}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic beam search + T (most probable candidate)"
      ],
      "metadata": {
        "id": "52u8sHqK_hw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(kBeams, maxOutputLen, candidatesAndProb, T=1.0):\n",
        "\n",
        "  candidates = candidatesAndProb[0]\n",
        "  probabilities = candidatesAndProb[1]\n",
        "\n",
        "  if maxOutputLen < 1:\n",
        "    return candidates, probabilities\n",
        "  else:\n",
        "    for curr in candidates:\n",
        "      out = pad_sequences([curr], maxlen=maxLen)\n",
        "      out = model.predict(out, verbose=0) #Probabilidades\n",
        "      temp = changeTemp(out[0], temperature=T)\n",
        "      newCandidates = np.argsort(temp)[::-1][:kBeams] #Agarramos los indices de los k-elementos con mas prob\n",
        "      newCandidates = [[num] for num in newCandidates] #Convertimos los numeros en listas de numeros por compatibilidad con pad_sequences\n",
        "      newCandProba = [temp[i] for i in newCandidates] #Agarramos su probabilidad\n",
        "\n",
        "      concatenated = np.concatenate((candidates, newCandidates), axis=1)\n",
        "      probabilities = np.multiply(probabilities, newCandProba)\n",
        "\n",
        "      return beam_search(kBeams, maxOutputLen-1, (concatenated, probabilities))"
      ],
      "metadata": {
        "id": "f9HvDsWP_lcW"
      },
      "execution_count": 674,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = token.texts_to_sequences([\"<sos> watson was walking\"])"
      ],
      "metadata": {
        "id": "Sg-vfcAE_v4V"
      },
      "execution_count": 675,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxOutputLen = 10\n",
        "kBeams = 5\n",
        "candidates = (question*kBeams, 1*kBeams)\n",
        "\n",
        "outSeq, outProb = beam_search(kBeams, maxOutputLen, candidates, T=1.1)\n",
        "result = token.sequences_to_texts(outSeq)\n",
        "\n",
        "for i, sent in enumerate(result):\n",
        "  print(f\"prob: {outProb[i][0]:.10f} - Rta: {sent}\")"
      ],
      "metadata": {
        "id": "sTgCEJGL_w4t",
        "outputId": "3213ff2a-ce5d-4808-e9d5-7bf3cb92f10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 680,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob: 0.0000000000 - Rta: <sos> watson was walking into the room and i have been a very man\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking in a door in the had not in little good\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking at his house which a was heard at few little\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking and my window at that am no to man few\n",
            "prob: 0.0000000000 - Rta: <sos> watson was walking down this other with was shall a not small very\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f420786d0a574b3ca83d292cee46598f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b326df92dc2449f1b59bc465eaa22c73",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d413ec225b2446fbbe79281979d78e7d",
            "value": 990000
          }
        },
        "b326df92dc2449f1b59bc465eaa22c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d413ec225b2446fbbe79281979d78e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}