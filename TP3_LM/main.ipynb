{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textit{Predicci√≥n a nivel de palabra}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import wget\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
    "filename = wget.download(url=url)\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Sherlock.txt\", 'r', encoding='utf-8') as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=30000,\n",
    "                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
    "                  split=' ', char_level=False, oov_token=\"UNK\",\n",
    "                  document_count=0)\n",
    "\n",
    "token.fit_on_texts([book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(token.texts_to_sequences([book])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, window=100):\n",
    "  inputs = []\n",
    "  outputs = []\n",
    "  \n",
    "  for i in range(len(text)-window):\n",
    "    inputs.append(text[i:i+window])\n",
    "    outputs.append(text[i+1:i+window+1])\n",
    "  return list(inputs), list(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "X, y = create_dataset(sequences, window_size) #Creamos una secuencia de largo window, con el texto de referencia en X y el texto mas 1 dato mas en y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, Reshape, BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def get_model(dropout_p = 0.1, output = len(chars), input_shape = (100, 71), RNN_units=200):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(RNN_units, input_shape=input_shape, return_sequences=True, name='RNN',\n",
    "                        dropout=dropout_p, recurrent_dropout=dropout_p ))\n",
    "    model.add(Dense(output, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
